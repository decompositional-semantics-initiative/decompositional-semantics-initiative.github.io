---
layout: project
handle: genericity
search_omit: true
---

An important line of study in formal semantics, philosophy, and AI investigates how language is used to represent knowledge of kinds, regularities and patterns. For instance, how do we know that *lions roar* describes a generalization about a kind of thing (lions), while *those lions roared* describes a specific event in which particular lions participated?

In this line of work, we annotate both predicates and their arguments for kind v. individual reference and construct models for predicting this distinction. This approach moves beyond the traditional classification of sentences into generics, habituals, and episodics by decomposing these classes into component parts based in referential phenomena.

For a detailed description of the protocols, datasets as well as models of these data, please see the following papers:

> V. S. Govindarajan, B. Van Durme. 2016, & White, A. S. [Decomposing Generalization: Models of Generic, Habitual, and Episodic Statements](). In *Arxiv*.

The code for generating the dataset files for Amazon Mechanical Turk(along with the stylesheets) can be found [here](https://github.com/FACTSlab/factslab-protocols). The code for the experiments described in the paper can be found [here](https://github.com/FACTSlab/factslab-protocols)
